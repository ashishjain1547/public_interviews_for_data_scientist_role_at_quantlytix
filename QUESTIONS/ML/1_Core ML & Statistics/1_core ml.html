<head>
    <script crossorigin="anonymous" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4="
        src="https://code.jquery.com/jquery-3.2.1.min.js"></script>
    
    <!-- Google AdSense Using Machine Learning Code -->
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
        (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-3071098372371409",
            enable_page_level_ads: true
        });
    </script>
    
    <script>
        $(document).ready(function () {
            $.ajax({
                url: "https://raw.githubusercontent.com/ashishjain1547/pubLessonsInTechnology/main/links_to_tech_clubs.json",
                success: function (result) {
                    let grouplink = JSON.parse(result)['Beta Tech Club'];
                    $("#customWhatsAppGroupLinkWrapper").html(
                        `
                        <h2 class="custom_link_h2"><a href="${grouplink}" target="_blank"> 
                            <span>Join us on:</span>
                            <span class="customLink"><i class="fa fa-whatsapp"></i> Whatsapp </span>
                            </a>
                        </h2>
                        `
                    );
                }
            });
        });
    </script>
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    
    <style>
        pre {
            white-space: pre-wrap;
            white-space: -moz-pre-wrap;
            white-space: -pre-wrap;
            white-space: -o-pre-wrap;
            word-wrap: break-word;
        }
    
        .customLink {
            background-color: #4CAF50;
            border: none;
            color: white !important;
            padding: 8px 13px;
            text-align: center;
            text-decoration: none;
            display: inline-block;
            font-size: 14px;
            margin: 4px 2px;
            cursor: pointer;
        }
    
        .customLink:hover {
            text-decoration: none;
        }
    
        div.code-block-decoration.footer {
            display: none;
        }
    
        button.export-sheets-button-wrapper {
            display: none;
        }
    </style>
    
    <style>
        .custom_link_h2 a {
            color: black;
            text-decoration: none;
            text-align: center;
        }
    
        .custom_link_h2 a:hover {
            color: black;
        }
    
        .custom_link_h2 a:active {
            color: black;
        }
    
        .custom_link_h2 span {
            translate: 0px -5px;
            display: inline-block;
        }
    
        .custom_link_h2 img {
            width: 100px;
            padding: 0px;
            border: none;
            box-shadow: none;
        }
    </style>
    <style>
        .customul {
            list-style: none;
        }
    
        [aria-hidden='true'] {
            display: none;
        }
    
        .custom_iframe {
            width: 100%;
            height: 305px;
        }
    
        i.ir { color: red; }
        i.ig { color: green; }
        i.ib { color: blue; }
        i.im { color: magenta; }
        i.ip { color: purple; }
    
        .customTable td {
            padding: 2px;
        }
    
        i.green {
            color: green;
        }
    
        i.red {
            color: red;
        }
    
        i.blue {
            color: blue;
        }
    
        button.flex.gap-1.items-center.select-none.px-4.py-1 {
            display: none;
        }
    
        button.flex.select-none.items-center.gap-1 {
            display: none;
        }

        button.bg-token-bg-primary {
            display: none;
        }
    
        .flex.items-center {
            display: none;
        }

        span.katex-html {
            display: none;
        }

    </style>
</head>

<div id="customWhatsAppGroupLinkWrapper"></div>

To See All Articles About Technology: <a class="customLink" href="https://survival8.blogspot.com/p/index-of-lessons-in-technology.html" target="_blank">Index of Lessons in Technology</a>

<br>

<div class="separator" style="clear: both;"><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgvVm8LrJwRw61vDoWE4Sa60Vw2div3UqAEpI6GT8U_1PM6e5bg8Am6KcY8mxnFGhMGA_u5yyx48CyXp_w-ogVZ7sklChB2XG0zcyUqnihV_FySpa0mWxPEfBm1L-QWGCxfyhrFmw4C451WVQDtYcFyN24ltwtJ2TqG4XFiK6Sl_Cd2zeRQNXZDS8BKhpM7/s1024/machine%20learning%20interview.jpg" style="display: block; padding: 1em 0; text-align: center; "><img alt="" border="0" width="600" data-original-height="724" data-original-width="1024" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgvVm8LrJwRw61vDoWE4Sa60Vw2div3UqAEpI6GT8U_1PM6e5bg8Am6KcY8mxnFGhMGA_u5yyx48CyXp_w-ogVZ7sklChB2XG0zcyUqnihV_FySpa0mWxPEfBm1L-QWGCxfyhrFmw4C451WVQDtYcFyN24ltwtJ2TqG4XFiK6Sl_Cd2zeRQNXZDS8BKhpM7/s600/machine%20learning%20interview.jpg"/></a></div>

<pre><b>LLM Used</b>: ChatGPT leveraging GPT-4.5 as in May 2025.</pre>

<h2>How do you choose between bias and variance in model training?</h2>

<div class="markdown prose dark:prose-invert w-full break-words light"><p data-start="0" data-end="197" class="">Great question! Choosing between <strong data-start="33" data-end="41">bias</strong> and <strong data-start="46" data-end="58">variance</strong> is essentially about managing the <strong data-start="93" data-end="105">tradeoff</strong> between underfitting and overfitting during model training. Here's how you can approach it:</p>
    <hr data-start="199" data-end="202" class="" style="">
    <h3 data-start="204" data-end="242" class="">‚öñÔ∏è <strong data-start="211" data-end="242">Understanding the Trade-off</strong></h3>
    <div class="pointer-events-none relative left-[50%] flex w-[100cqw] translate-x-[-50%] justify-center *:pointer-events-auto"><div class="tableContainer horzScrollShadows"><table class="min-w-full" data-start="244" data-end="530"><thead data-start="244" data-end="284"><tr data-start="244" data-end="284"><th data-start="244" data-end="255">Term</th><th data-start="255" data-end="269">Description</th><th data-start="269" data-end="284">Consequence</th></tr></thead><tbody data-start="326" data-end="530"><tr data-start="326" data-end="428"><td class="" data-start="326" data-end="341"><strong data-start="328" data-end="336">Bias</strong></td><td class="min-w-[calc(var(--thread-content-max-width)/3)]" data-start="341" data-end="399">Error due to overly simplistic assumptions in the model</td><td class="" data-start="399" data-end="428">Leads to <strong data-start="410" data-end="426">underfitting</strong></td></tr><tr data-start="429" data-end="530"><td class="" data-start="429" data-end="444"><strong data-start="431" data-end="443">Variance</strong></td><td class="min-w-[calc(var(--thread-content-max-width)/3)]" data-start="444" data-end="502">Error due to model being too sensitive to training data</td><td class="" data-start="502" data-end="530">Leads to <strong data-start="513" data-end="528">overfitting</strong></td></tr></tbody></table></div></div>
    <hr data-start="532" data-end="535" class="" style="">
    <h3 data-start="537" data-end="576" class="">üß† <strong data-start="544" data-end="576">How to Choose / Balance Them</strong></h3>
    <p data-start="578" data-end="718" class="">You don‚Äôt choose one <strong data-start="599" data-end="607">over</strong> the other ‚Äî you try to <strong data-start="631" data-end="647">balance both</strong> to achieve <strong data-start="659" data-end="678">low total error</strong> (bias¬≤ + variance + irreducible error).</p>
    <h4 data-start="720" data-end="758" class="">‚úÖ Steps to Handle It Practically:</h4>
    <ol data-start="760" data-end="1652">
    <li data-start="760" data-end="957" class="" style="">
    <p data-start="763" data-end="788" class=""><strong data-start="763" data-end="788">Check Learning Curves</strong></p>
    <ul data-start="792" data-end="957">
    <li data-start="792" data-end="867" class="" style="">
    <p data-start="794" data-end="867" class="">If both training and validation error are high ‚Üí high bias (underfitting)</p>
    </li>
    <li data-start="871" data-end="957" class="" style="">
    <p data-start="873" data-end="957" class="">If training error is low, but validation error is high ‚Üí high variance (overfitting)</p>
    </li>
    </ul>
    </li>
    <li data-start="959" data-end="1316" class="" style="">
    <p data-start="962" data-end="982" class=""><strong data-start="962" data-end="982">Model Complexity</strong></p>
    <ul data-start="986" data-end="1316">
    <li data-start="986" data-end="1056" class="" style="">
    <p data-start="988" data-end="1056" class="">Simple models (like linear regression) = lower variance, higher bias</p>
    </li>
    <li data-start="1060" data-end="1130" class="" style="">
    <p data-start="1062" data-end="1130" class="">Complex models (like deep neural nets) = lower bias, higher variance</p>
    </li>
    <li data-start="1134" data-end="1316" class="" style="">
    <p data-start="1136" data-end="1180" class="">Choose based on dataset size and complexity:</p>
    <ul data-start="1186" data-end="1316">
    <li data-start="1186" data-end="1243" class="" style="">
    <p data-start="1188" data-end="1243" class=""><strong data-start="1188" data-end="1243">Small data ‚Üí simpler model (to avoid high variance)</strong></p>
    </li>
    <li data-start="1249" data-end="1316" class="" style="">
    <p data-start="1251" data-end="1316" class=""><strong data-start="1251" data-end="1316">Large data ‚Üí can use complex models (variance can be managed)</strong></p>
    </li>
    </ul>
    </li>
    </ul>
    </li>
    <li data-start="1318" data-end="1502" class="" style="">
    <p data-start="1321" data-end="1343" class=""><strong data-start="1321" data-end="1343">Use Regularization</strong></p>
    <ul data-start="1347" data-end="1502">
    <li data-start="1347" data-end="1439" class="" style="">
    <p data-start="1349" data-end="1439" class="">Techniques like <strong data-start="1365" data-end="1389">L1/L2 regularization</strong> reduce variance without increasing bias too much.</p>
    </li>
    <li data-start="1443" data-end="1502" class="" style="">
    <p data-start="1445" data-end="1502" class="">Dropout in neural networks is a variance-reducing method.</p>
    </li>
    </ul>
    </li>
    <li data-start="1504" data-end="1611" class="" style="">
    <p data-start="1507" data-end="1527" class=""><strong data-start="1507" data-end="1527">Cross-Validation</strong></p>
    <ul data-start="1531" data-end="1611">
    <li data-start="1531" data-end="1611" class="" style="">
    <p data-start="1533" data-end="1611" class="">Helps estimate generalization error and pick models that minimize overfitting.</p>
    </li>
    </ul>
    </li>
    <li data-start="1613" data-end="1652" class="" style="">
    <p data-start="1616" data-end="1652" class=""><strong data-start="1616" data-end="1639">Bias‚ÄìVariance Table</strong> (Intuition):</p>
    </li>
    </ol>
    <div class="pointer-events-none relative left-[50%] flex w-[100cqw] translate-x-[-50%] justify-center *:pointer-events-auto"><div class="tableContainer horzScrollShadows"><table class="min-w-full" data-start="1654" data-end="1923"><thead data-start="1654" data-end="1698"><tr data-start="1654" data-end="1698"><th data-start="1654" data-end="1675">Model Type</th><th data-start="1675" data-end="1686">Bias</th><th data-start="1686" data-end="1698">Variance</th></tr></thead><tbody data-start="1744" data-end="1923"><tr data-start="1744" data-end="1788"><td class="" data-start="1744" data-end="1765">Linear Regression</td><td class="" data-start="1765" data-end="1776">High</td><td class="" data-start="1776" data-end="1788">Low</td></tr><tr data-start="1789" data-end="1833"><td class="" data-start="1789" data-end="1810">Decision Tree</td><td class="" data-start="1810" data-end="1821">Low</td><td class="" data-start="1821" data-end="1833">High</td></tr><tr data-start="1834" data-end="1878"><td class="" data-start="1834" data-end="1855">Random Forest</td><td class="" data-start="1855" data-end="1866">Low</td><td class="" data-start="1866" data-end="1878">Moderate</td></tr><tr data-start="1879" data-end="1923"><td class="" data-start="1879" data-end="1900">Neural Networks</td><td class="" data-start="1900" data-end="1911">Low</td><td class="" data-start="1911" data-end="1923">High</td></tr></tbody></table></div></div>
    <hr data-start="1925" data-end="1928" class="" style="">
    <h3 data-start="1930" data-end="1944" class="">üéØ Summary</h3>
    <p data-start="1946" data-end="2001" class="">You don‚Äôt "choose" one ‚Äî you manage the <strong data-start="1986" data-end="1997">balance</strong> by:</p>
    <ul data-start="2002" data-end="2148">
    <li data-start="2002" data-end="2049" class="" style="">
    <p data-start="2004" data-end="2049" class="">Selecting the right level of model complexity</p>
    </li>
    <li data-start="2050" data-end="2093" class="" style="">
    <p data-start="2052" data-end="2093" class="">Using regularization and cross-validation</p>
    </li>
    <li data-start="2094" data-end="2148" class="" style="">
    <p data-start="2096" data-end="2148" class="">Analyzing learning curves to guide model adjustments</p>
    </li>
    </ul>
    <p data-start="2150" data-end="2230" class="">Let me know if you'd like help visualizing this with a graph or example dataset!</p></div>

<h2>What is regularization? Explain L1 vs. L2.</h2>

<div class="markdown prose dark:prose-invert w-full break-words light"><p data-start="0" data-end="142" class="">Great question! <strong data-start="16" data-end="34">Regularization</strong> is a key concept in machine learning used to <strong data-start="80" data-end="103">prevent overfitting</strong> by discouraging overly complex models.</p>
    <hr data-start="144" data-end="147" class="" style="">
    <h3 data-start="149" data-end="178" class="">‚úÖ What is Regularization?</h3>
    <p data-start="180" data-end="276" class="">Regularization adds a <strong data-start="202" data-end="218">penalty term</strong> to the loss function used to train a model. This penalty:</p>
    <ul data-start="277" data-end="409">
    <li data-start="277" data-end="343" class="" style="">
    <p data-start="279" data-end="343" class=""><strong data-start="279" data-end="343">Constrains the magnitude of the model‚Äôs parameters (weights)</strong></p>
    </li>
    <li data-start="344" data-end="409" class="" style="">
    <p data-start="346" data-end="409" class="">Encourages simpler models that generalize better to unseen data</p>
    </li>
    </ul>
    <hr data-start="411" data-end="414" class="" style="">
    <h3 data-start="416" data-end="468" class="">üßÆ Standard Loss Function (e.g., for regression)</h3>
    <pre class="overflow-visible!" data-start="469" data-end="526"><div class="contain-inline-size rounded-md border-[0.5px] border-token-border-medium relative bg-token-sidebar-surface-primary"><div class="flex items-center text-token-text-secondary px-4 py-2 text-xs font-sans justify-between h-9 bg-token-sidebar-surface-primary dark:bg-token-main-surface-secondary select-none rounded-t-[5px]">text</div><div class="sticky top-9"><div class="absolute end-0 bottom-0 flex h-9 items-center pe-2"><div class="bg-token-sidebar-surface-primary text-token-text-secondary dark:bg-token-main-surface-secondary flex items-center rounded-sm px-2 font-sans text-xs"><span class="" data-state="closed"><button class="flex gap-1 items-center select-none px-4 py-1" aria-label="Copy"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" class="icon-xs"><path fill-rule="evenodd" clip-rule="evenodd" d="M7 5C7 3.34315 8.34315 2 10 2H19C20.6569 2 22 3.34315 22 5V14C22 15.6569 20.6569 17 19 17H17V19C17 20.6569 15.6569 22 14 22H5C3.34315 22 2 20.6569 2 19V10C2 8.34315 3.34315 7 5 7H7V5ZM9 7H14C15.6569 7 17 8.34315 17 10V15H19C19.5523 15 20 14.5523 20 14V5C20 4.44772 19.5523 4 19 4H10C9.44772 4 9 4.44772 9 5V7ZM5 9C4.44772 9 4 9.44772 4 10V19C4 19.5523 4.44772 20 5 20H14C14.5523 20 15 19.5523 15 19V10C15 9.44772 14.5523 9 14 9H5Z" fill="currentColor"></path></svg>Copy</button></span><span class="" data-state="closed"><button class="flex items-center gap-1 px-4 py-1 select-none"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" class="icon-xs"><path d="M2.5 5.5C4.3 5.2 5.2 4 5.5 2.5C5.8 4 6.7 5.2 8.5 5.5C6.7 5.8 5.8 7 5.5 8.5C5.2 7 4.3 5.8 2.5 5.5Z" fill="currentColor" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path><path d="M5.66282 16.5231L5.18413 19.3952C5.12203 19.7678 5.09098 19.9541 5.14876 20.0888C5.19933 20.2067 5.29328 20.3007 5.41118 20.3512C5.54589 20.409 5.73218 20.378 6.10476 20.3159L8.97693 19.8372C9.72813 19.712 10.1037 19.6494 10.4542 19.521C10.7652 19.407 11.0608 19.2549 11.3343 19.068C11.6425 18.8575 11.9118 18.5882 12.4503 18.0497L20 10.5C21.3807 9.11929 21.3807 6.88071 20 5.5C18.6193 4.11929 16.3807 4.11929 15 5.5L7.45026 13.0497C6.91175 13.5882 6.6425 13.8575 6.43197 14.1657C6.24513 14.4392 6.09299 14.7348 5.97903 15.0458C5.85062 15.3963 5.78802 15.7719 5.66282 16.5231Z" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></path><path d="M14.5 7L18.5 11" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></path></svg>Edit</button></span></div></div></div><div class="overflow-y-auto p-4" dir="ltr"><code class="whitespace-pre! language-text"><span><span>Loss = Error (like MSE) + Regularization term
    </span></span></code></div></div></pre>
    <hr data-start="528" data-end="531" class="" style="">
    <h3 data-start="533" data-end="564" class="">üîç L1 vs. L2 Regularization</h3>
    <div class="pointer-events-none relative left-[50%] flex w-[100cqw] translate-x-[-50%] justify-center *:pointer-events-auto"><div class="tableContainer horzScrollShadows"><table class="min-w-full" data-start="566" data-end="1209"><thead data-start="566" data-end="670"><tr data-start="566" data-end="670"><th data-start="566" data-end="590">Feature</th><th data-start="590" data-end="629"><strong data-start="592" data-end="621">L1 Regularization (Lasso)</strong></th><th data-start="629" data-end="670"><strong data-start="631" data-end="660">L2 Regularization (Ridge)</strong></th></tr></thead><tbody data-start="776" data-end="1209"><tr data-start="776" data-end="880"><td class="" data-start="776" data-end="800">Penalty term</td><td class="" data-start="800" data-end="808">`Œª * Œ£</td><td class="" data-start="808" data-end="810">w</td></tr><tr data-start="881" data-end="999"><td class="" data-start="881" data-end="905">Effect on weights</td><td class="" data-start="905" data-end="944">Can shrink some weights <strong data-start="931" data-end="942">to zero</strong></td><td class="min-w-[calc(var(--thread-content-max-width)/3)]" data-start="944" data-end="999">Shrinks weights close to zero, but not exactly zero</td></tr><tr data-start="1000" data-end="1104"><td class="" data-start="1000" data-end="1024">Feature selection</td><td class="" data-start="1024" data-end="1063"><strong data-start="1026" data-end="1033">Yes</strong> ‚Äì leads to sparse models</td><td class="" data-start="1063" data-end="1104"><strong data-start="1065" data-end="1071">No</strong> ‚Äì keeps all features</td></tr><tr data-start="1105" data-end="1209"><td class="" data-start="1105" data-end="1129">Optimization</td><td class="" data-start="1129" data-end="1168">Not differentiable at 0</td><td class="" data-start="1168" data-end="1209">Differentiable, easier to optimize</td></tr></tbody></table></div></div>
    <blockquote data-start="1211" data-end="1288">
    <p data-start="1213" data-end="1288" class="">üîß Œª (lambda) is the regularization strength ‚Äì higher Œª means more penalty.</p>
    </blockquote>
    <hr data-start="1290" data-end="1293" class="" style="">
    <h3 data-start="1295" data-end="1318" class="">üî¢ Visual Intuition</h3>
    <ul data-start="1320" data-end="1501">
    <li data-start="1320" data-end="1421" class="" style="">
    <p data-start="1322" data-end="1421" class=""><strong data-start="1322" data-end="1328">L1</strong> gives a <strong data-start="1337" data-end="1355">diamond-shaped</strong> constraint ‚Äì solution often lands on axes ‚Üí some weights become 0</p>
    </li>
    <li data-start="1422" data-end="1501" class="" style="">
    <p data-start="1424" data-end="1501" class=""><strong data-start="1424" data-end="1430">L2</strong> gives a <strong data-start="1439" data-end="1462">circular constraint</strong> ‚Äì tends to shrink all weights smoothly</p>
    </li>
    </ul>
    <hr data-start="1503" data-end="1506" class="" style="">
    <h3 data-start="1508" data-end="1526" class="">üìå When to Use</h3>
    <div class="pointer-events-none relative left-[50%] flex w-[100cqw] translate-x-[-50%] justify-center *:pointer-events-auto"><div class="tableContainer horzScrollShadows"><table class="min-w-full" data-start="1528" data-end="1866"><thead data-start="1528" data-end="1593"><tr data-start="1528" data-end="1593"><th data-start="1528" data-end="1563">Situation</th><th data-start="1563" data-end="1593">Recommended Regularization</th></tr></thead><tbody data-start="1660" data-end="1866"><tr data-start="1660" data-end="1724"><td class="" data-start="1660" data-end="1694">You want <strong data-start="1671" data-end="1692">feature selection</strong></td><td class="" data-start="1694" data-end="1724">L1 (Lasso)</td></tr><tr data-start="1725" data-end="1801"><td class="" data-start="1725" data-end="1772">You want <strong data-start="1736" data-end="1756">smooth/shrinkage</strong> of all weights</td><td class="" data-start="1772" data-end="1801">L2 (Ridge)</td></tr><tr data-start="1802" data-end="1866"><td class="" data-start="1802" data-end="1836">You want the best of both</td><td class="" data-start="1836" data-end="1866">ElasticNet (L1 + L2 combo)</td></tr></tbody></table></div></div>
    <hr data-start="1868" data-end="1871" class="" style="">
    <h3 data-start="1873" data-end="1887" class="">üß† Summary</h3>
    <ul data-start="1889" data-end="2080">
    <li data-start="1889" data-end="1958" class="" style="">
    <p data-start="1891" data-end="1958" class=""><strong data-start="1891" data-end="1909">Regularization</strong> reduces overfitting by penalizing large weights.</p>
    </li>
    <li data-start="1959" data-end="2019" class="" style="">
    <p data-start="1961" data-end="2019" class=""><strong data-start="1961" data-end="1975">L1 (Lasso)</strong>: Sparse models, good for feature selection.</p>
    </li>
    <li data-start="2020" data-end="2080" class="" style="">
    <p data-start="2022" data-end="2080" class=""><strong data-start="2022" data-end="2036">L2 (Ridge)</strong>: Keeps all features, smoother weight decay.</p>
    </li>
    </ul>
    <p data-start="2082" data-end="2151" class="">Let me know if you'd like a code example to visualize the difference!</p></div>

<h2>Explain precision, recall, F1-score, and when you‚Äôd prioritize one over the other.</h2>

<div class="markdown prose dark:prose-invert w-full break-words light"><p data-start="0" data-end="215" class="">Great! Let‚Äôs break down <strong data-start="24" data-end="37">Precision</strong>, <strong data-start="39" data-end="49">Recall</strong>, and <strong data-start="55" data-end="67">F1-score</strong>‚Äîthey‚Äôre critical metrics for evaluating classification models, especially when classes are imbalanced or costs of false positives/negatives differ.</p>
    <hr data-start="217" data-end="220" class="" style="">
    <h3 data-start="222" data-end="279" class="">üìä Confusion Matrix Refresher (Binary Classification)</h3>
    <div class="pointer-events-none relative left-[50%] flex w-[100cqw] translate-x-[-50%] justify-center *:pointer-events-auto"><div class="tableContainer horzScrollShadows"><table class="min-w-full" data-start="281" data-end="552"><thead data-start="281" data-end="341"><tr data-start="281" data-end="341"><th data-start="281" data-end="298"></th><th data-start="298" data-end="319">Predicted Positive</th><th data-start="319" data-end="341">Predicted Negative</th></tr></thead><tbody data-start="403" data-end="552"><tr data-start="403" data-end="477"><td class="" data-start="403" data-end="425"><strong data-start="405" data-end="424">Actual Positive</strong></td><td class="" data-start="425" data-end="450">True Positive (TP)</td><td class="" data-start="450" data-end="477">False Negative (FN)</td></tr><tr data-start="478" data-end="552"><td class="" data-start="478" data-end="500"><strong data-start="480" data-end="499">Actual Negative</strong></td><td class="" data-start="500" data-end="525">False Positive (FP)</td><td class="" data-start="525" data-end="552">True Negative (TN)</td></tr></tbody></table></div></div>
    <hr data-start="554" data-end="557" class="" style="">
    <h3 data-start="559" data-end="574" class="">‚úÖ Precision</h3>
    <blockquote data-start="576" data-end="648">
    <p data-start="578" data-end="648" class=""><strong data-start="578" data-end="648">"Out of all predicted positives, how many were actually positive?"</strong></p>
    </blockquote>
    <span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>Precision</mtext><mo>=</mo><mfrac><mrow><mi>T</mi><mi>P</mi></mrow><mrow><mi>T</mi><mi>P</mi><mo>+</mo><mi>F</mi><mi>P</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">\text{Precision} = \frac{TP}{TP + FP}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.6833em;"></span><span class="mord text"><span class="mord">Precision</span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 2.1297em; vertical-align: -0.7693em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.3603em;"><span style="top: -2.314em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.13889em;">TP</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mord mathnormal" style="margin-right: 0.13889em;">FP</span></span></span><span style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span style="top: -3.677em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.13889em;">TP</span></span></span></span><span class="vlist-s">‚Äã</span></span><span class="vlist-r"><span class="vlist" style="height: 0.7693em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span>
    <ul data-start="695" data-end="829">
    <li data-start="695" data-end="741" class="" style="">
    <p data-start="697" data-end="741" class=""><strong data-start="697" data-end="715">High precision</strong> = low false positive rate</p>
    </li>
    <li data-start="742" data-end="829" class="" style="">
    <p data-start="744" data-end="829" class="">Prioritize when <strong data-start="760" data-end="790">false positives are costly</strong> (e.g., spam filters, cancer diagnosis)</p>
    </li>
    </ul>
    <hr data-start="831" data-end="834" class="" style="">
    <h3 data-start="836" data-end="883" class="">‚úÖ Recall (Sensitivity / True Positive Rate)</h3>
    <blockquote data-start="885" data-end="957">
    <p data-start="887" data-end="957" class=""><strong data-start="887" data-end="957">"Out of all actual positives, how many did we correctly identify?"</strong></p>
    </blockquote>
    <span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>Recall</mtext><mo>=</mo><mfrac><mrow><mi>T</mi><mi>P</mi></mrow><mrow><mi>T</mi><mi>P</mi><mo>+</mo><mi>F</mi><mi>N</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">\text{Recall} = \frac{TP}{TP + FN}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.6944em;"></span><span class="mord text"><span class="mord">Recall</span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 2.1297em; vertical-align: -0.7693em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.3603em;"><span style="top: -2.314em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.13889em;">TP</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mord mathnormal" style="margin-right: 0.10903em;">FN</span></span></span><span style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span style="top: -3.677em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.13889em;">TP</span></span></span></span><span class="vlist-s">‚Äã</span></span><span class="vlist-r"><span class="vlist" style="height: 0.7693em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span>
    <ul data-start="1001" data-end="1136">
    <li data-start="1001" data-end="1044" class="" style="">
    <p data-start="1003" data-end="1044" class=""><strong data-start="1003" data-end="1018">High recall</strong> = low false negative rate</p>
    </li>
    <li data-start="1045" data-end="1136" class="" style="">
    <p data-start="1047" data-end="1136" class="">Prioritize when <strong data-start="1063" data-end="1093">false negatives are costly</strong> (e.g., fraud detection, medical screening)</p>
    </li>
    </ul>
    <hr data-start="1138" data-end="1141" class="" style="">
    <h3 data-start="1143" data-end="1157" class="">‚úÖ F1-Score</h3>
    <blockquote data-start="1159" data-end="1259">
    <p data-start="1161" data-end="1259" class=""><strong data-start="1161" data-end="1204">"Harmonic mean of precision and recall"</strong><br data-start="1204" data-end="1207">
    Balances the trade-off between precision and recall.</p>
    </blockquote>
    <span class="katex-display" style=""><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>F</mi><mn>1</mn><mo>=</mo><mn>2</mn><mo>‚ãÖ</mo><mfrac><mrow><mtext>Precision</mtext><mo>‚ãÖ</mo><mtext>Recall</mtext></mrow><mrow><mtext>Precision</mtext><mo>+</mo><mtext>Recall</mtext></mrow></mfrac></mrow><annotation encoding="application/x-tex">F1 = 2 \cdot \frac{\text{Precision} \cdot \text{Recall}}{\text{Precision} + \text{Recall}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.6833em;"></span><span class="mord mathnormal" style="margin-right: 0.13889em;">F</span><span class="mord">1</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.6444em;"></span><span class="mord">2</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">‚ãÖ</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 2.1408em; vertical-align: -0.7693em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.3714em;"><span style="top: -2.314em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord text"><span class="mord">Precision</span></span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mord text"><span class="mord">Recall</span></span></span></span><span style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span style="top: -3.677em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord text"><span class="mord">Precision</span></span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">‚ãÖ</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mord text"><span class="mord">Recall</span></span></span></span></span><span class="vlist-s">‚Äã</span></span><span class="vlist-r"><span class="vlist" style="height: 0.7693em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span>
    <ul data-start="1359" data-end="1494">
    <li data-start="1359" data-end="1429" class="" style="">
    <p data-start="1361" data-end="1429" class="">Use when you want a <strong data-start="1381" data-end="1399">balanced score</strong> between precision and recall.</p>
    </li>
    <li data-start="1430" data-end="1494" class="" style="">
    <p data-start="1432" data-end="1494" class="">Useful in <strong data-start="1442" data-end="1465">imbalanced datasets</strong> (e.g., rare event detection)</p>
    </li>
    </ul>
    <hr data-start="1496" data-end="1499" class="" style="">
    <h3 data-start="1501" data-end="1532" class="">üß† When to Prioritize What?</h3>
    <div class="pointer-events-none relative left-[50%] flex w-[100cqw] translate-x-[-50%] justify-center *:pointer-events-auto"><div class="tableContainer horzScrollShadows"><table class="min-w-full" data-start="1534" data-end="2229"><thead data-start="1534" data-end="1601"><tr data-start="1534" data-end="1601"><th data-start="1534" data-end="1570">Use Case</th><th data-start="1570" data-end="1593">Metric to Prioritize</th><th data-start="1593" data-end="1601">Why?</th></tr></thead><tbody data-start="1669" data-end="2229"><tr data-start="1669" data-end="1788"><td class="" data-start="1669" data-end="1704">Spam detection</td><td class="" data-start="1704" data-end="1727"><strong data-start="1706" data-end="1719">Precision</strong></td><td class="min-w-[calc(var(--thread-content-max-width)/3)]" data-start="1727" data-end="1788">False positives (real emails marked as spam) are annoying</td></tr><tr data-start="1789" data-end="1899"><td class="" data-start="1789" data-end="1824">Disease screening (e.g., cancer)</td><td class="" data-start="1824" data-end="1847"><strong data-start="1826" data-end="1836">Recall</strong></td><td class="min-w-[calc(var(--thread-content-max-width)/3)]" data-start="1847" data-end="1899">False negatives (missed diagnoses) are dangerous</td></tr><tr data-start="1900" data-end="2030"><td class="" data-start="1900" data-end="1935">Fraud detection</td><td class="" data-start="1935" data-end="1958"><strong data-start="1937" data-end="1947">Recall</strong> or <strong data-start="1951" data-end="1957">F1</strong></td><td class="min-w-[calc(var(--thread-content-max-width)/3)]" data-start="1958" data-end="2030">Missing fraud is costly (FN); F1 helps balance if both are important</td></tr><tr data-start="2031" data-end="2135"><td class="" data-start="2031" data-end="2066">Job recommendation systems</td><td class="" data-start="2066" data-end="2089"><strong data-start="2068" data-end="2081">Precision</strong></td><td class="min-w-[calc(var(--thread-content-max-width)/3)]" data-start="2089" data-end="2135">Show fewer, but more relevant, job matches</td></tr><tr data-start="2136" data-end="2229"><td class="" data-start="2136" data-end="2171">Search engines</td><td class="" data-start="2171" data-end="2194"><strong data-start="2173" data-end="2186">Precision</strong></td><td class="" data-start="2194" data-end="2229">Only show most relevant results</td></tr></tbody></table></div></div>
    <hr data-start="2231" data-end="2234" class="" style="">
    <h3 data-start="2236" data-end="2248" class="">üîÅ TL;DR</h3>
    <ul data-start="2250" data-end="2436">
    <li data-start="2250" data-end="2309" class="" style="">
    <p data-start="2252" data-end="2309" class=""><strong data-start="2252" data-end="2265">Precision</strong>: "Don‚Äôt cry wolf" üê∫ ‚Äî avoid false alarms</p>
    </li>
    <li data-start="2310" data-end="2364" class="" style="">
    <p data-start="2312" data-end="2364" class=""><strong data-start="2312" data-end="2322">Recall</strong>: "Catch every wolf" üê∫ ‚Äî don‚Äôt miss any</p>
    </li>
    <li data-start="2365" data-end="2436" class="" style="">
    <p data-start="2367" data-end="2436" class=""><strong data-start="2367" data-end="2379">F1-Score</strong>: "Balance the two" ‚öñÔ∏è ‚Äî good when both errors are costly</p>
    </li>
    </ul>
    <p data-start="2438" data-end="2521" class="">Let me know if you'd like a small Python example or confusion matrix visualization!</p></div>

<h2>Can you share one simple numerical on Precision and Recall?</h2>

<h3>Find Precision and Recall for the below span email classifier problem.</h3>

<pre>
Out of 100 emails, 40 are spam mails
Model predicted 50 spam mails:
30 (correctly predicted spam)
20 (predicted spam, but not spam)
10 (actual spam, but predicted not spam)</pre>

<div class="flex w-full flex-col gap-1 empty:hidden first:pt-[3px]"><div class="markdown prose dark:prose-invert w-full break-words light"><p data-start="0" data-end="103" class="">Absolutely! Let's go through a <strong data-start="31" data-end="59">simple numerical example</strong> to understand <strong data-start="74" data-end="87">Precision</strong> and <strong data-start="92" data-end="102">Recall</strong>.</p>
    <hr data-start="105" data-end="108" class="">
    <h3 data-start="110" data-end="133" class="">üßÆ Example Scenario</h3>
    <p data-start="135" data-end="246" class="">Imagine you're building a <strong data-start="161" data-end="186">spam email classifier</strong>.<br data-start="187" data-end="190">
    Out of <strong data-start="197" data-end="211">100 emails</strong>, here‚Äôs what your model predicted:</p>
    <ul data-start="248" data-end="536">
    <li data-start="248" data-end="278" class="">
    <p data-start="250" data-end="278" class=""><strong data-start="250" data-end="272">Actual spam emails</strong>: 40</p>
    </li>
    <li data-start="279" data-end="320" class="">
    <p data-start="281" data-end="320" class=""><strong data-start="281" data-end="318">Model predicted 50 emails as spam</strong></p>
    </li>
    <li data-start="321" data-end="536" class="">
    <p data-start="323" data-end="339" class="">Out of those 50:</p>
    <ul data-start="342" data-end="536">
    <li data-start="342" data-end="399" class="">
    <p data-start="344" data-end="399" class=""><strong data-start="344" data-end="367">True Positives (TP)</strong> = 30 (correctly predicted spam)</p>
    </li>
    <li data-start="402" data-end="464" class="">
    <p data-start="404" data-end="464" class=""><strong data-start="404" data-end="428">False Positives (FP)</strong> = 20 (predicted spam, but not spam)</p>
    </li>
    <li data-start="467" data-end="536" class="">
    <p data-start="469" data-end="536" class=""><strong data-start="469" data-end="493">False Negatives (FN)</strong> = 10 (actual spam, but predicted not spam)</p>
    </li>
    </ul>
    </li>
    </ul>
    <p data-start="538" data-end="554" class="">Let‚Äôs calculate:</p>
    <hr data-start="556" data-end="559" class="">
    <h3 data-start="561" data-end="576" class="">‚úÖ Precision</h3>
    <span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>Precision</mtext><mo>=</mo><mfrac><mrow><mi>T</mi><mi>P</mi></mrow><mrow><mi>T</mi><mi>P</mi><mo>+</mo><mi>F</mi><mi>P</mi></mrow></mfrac><mo>=</mo><mfrac><mn>30</mn><mrow><mn>30</mn><mo>+</mo><mn>20</mn></mrow></mfrac><mo>=</mo><mfrac><mn>30</mn><mn>50</mn></mfrac><mo>=</mo><mn>0.6</mn></mrow><annotation encoding="application/x-tex">\text{Precision} = \frac{TP}{TP + FP} = \frac{30}{30 + 20} = \frac{30}{50} = 0.6</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.6833em;"></span><span class="mord text"><span class="mord">Precision</span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 2.1297em; vertical-align: -0.7693em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.3603em;"><span style="top: -2.314em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.13889em;">TP</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mord mathnormal" style="margin-right: 0.13889em;">FP</span></span></span><span style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span style="top: -3.677em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.13889em;">TP</span></span></span></span><span class="vlist-s">‚Äã</span></span><span class="vlist-r"><span class="vlist" style="height: 0.7693em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 2.0908em; vertical-align: -0.7693em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.3214em;"><span style="top: -2.314em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord">30</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mord">20</span></span></span><span style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span style="top: -3.677em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord">30</span></span></span></span><span class="vlist-s">‚Äã</span></span><span class="vlist-r"><span class="vlist" style="height: 0.7693em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 2.0074em; vertical-align: -0.686em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.3214em;"><span style="top: -2.314em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord">50</span></span></span><span style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span style="top: -3.677em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord">30</span></span></span></span><span class="vlist-s">‚Äã</span></span><span class="vlist-r"><span class="vlist" style="height: 0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.6444em;"></span><span class="mord">0.6</span></span></span></span></span>
    <blockquote data-start="666" data-end="731">
    <p data-start="668" data-end="731" class="">So, <strong data-start="672" data-end="679">60%</strong> of the emails predicted as spam were actually spam.</p>
    </blockquote>
    <hr data-start="733" data-end="736" class="">
    <h3 data-start="738" data-end="750" class="">‚úÖ Recall</h3>
    <span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>Recall</mtext><mo>=</mo><mfrac><mrow><mi>T</mi><mi>P</mi></mrow><mrow><mi>T</mi><mi>P</mi><mo>+</mo><mi>F</mi><mi>N</mi></mrow></mfrac><mo>=</mo><mfrac><mn>30</mn><mrow><mn>30</mn><mo>+</mo><mn>10</mn></mrow></mfrac><mo>=</mo><mfrac><mn>30</mn><mn>40</mn></mfrac><mo>=</mo><mn>0.75</mn></mrow><annotation encoding="application/x-tex">\text{Recall} = \frac{TP}{TP + FN} = \frac{30}{30 + 10} = \frac{30}{40} = 0.75</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.6944em;"></span><span class="mord text"><span class="mord">Recall</span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 2.1297em; vertical-align: -0.7693em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.3603em;"><span style="top: -2.314em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.13889em;">TP</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mord mathnormal" style="margin-right: 0.10903em;">FN</span></span></span><span style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span style="top: -3.677em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.13889em;">TP</span></span></span></span><span class="vlist-s">‚Äã</span></span><span class="vlist-r"><span class="vlist" style="height: 0.7693em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 2.0908em; vertical-align: -0.7693em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.3214em;"><span style="top: -2.314em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord">30</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mord">10</span></span></span><span style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span style="top: -3.677em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord">30</span></span></span></span><span class="vlist-s">‚Äã</span></span><span class="vlist-r"><span class="vlist" style="height: 0.7693em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 2.0074em; vertical-align: -0.686em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.3214em;"><span style="top: -2.314em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord">40</span></span></span><span style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span style="top: -3.677em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord">30</span></span></span></span><span class="vlist-s">‚Äã</span></span><span class="vlist-r"><span class="vlist" style="height: 0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.6444em;"></span><span class="mord">0.75</span></span></span></span></span>
    <blockquote data-start="838" data-end="909">
    <p data-start="840" data-end="909" class="">So, the model correctly identified <strong data-start="875" data-end="882">75%</strong> of all actual spam emails.</p>
    </blockquote>
    <hr data-start="911" data-end="914" class="">
    <h3 data-start="916" data-end="930" class="">‚úÖ F1 Score</h3>
    <span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>F1</mtext><mo>=</mo><mn>2</mn><mo>‚ãÖ</mo><mfrac><mrow><mn>0.6</mn><mo>‚ãÖ</mo><mn>0.75</mn></mrow><mrow><mn>0.6</mn><mo>+</mo><mn>0.75</mn></mrow></mfrac><mo>=</mo><mn>2</mn><mo>‚ãÖ</mo><mfrac><mn>0.45</mn><mn>1.35</mn></mfrac><mo>=</mo><mn>0.6667</mn></mrow><annotation encoding="application/x-tex">\text{F1} = 2 \cdot \frac{0.6 \cdot 0.75}{0.6 + 0.75} = 2 \cdot \frac{0.45}{1.35} = 0.6667</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.6833em;"></span><span class="mord text"><span class="mord">F1</span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.6444em;"></span><span class="mord">2</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">‚ãÖ</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 2.0908em; vertical-align: -0.7693em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.3214em;"><span style="top: -2.314em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord">0.6</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mord">0.75</span></span></span><span style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span style="top: -3.677em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord">0.6</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">‚ãÖ</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mord">0.75</span></span></span></span><span class="vlist-s">‚Äã</span></span><span class="vlist-r"><span class="vlist" style="height: 0.7693em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.6444em;"></span><span class="mord">2</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">‚ãÖ</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 2.0074em; vertical-align: -0.686em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.3214em;"><span style="top: -2.314em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord">1.35</span></span></span><span style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span style="top: -3.677em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord">0.45</span></span></span></span><span class="vlist-s">‚Äã</span></span><span class="vlist-r"><span class="vlist" style="height: 0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.6444em;"></span><span class="mord">0.6667</span></span></span></span></span>
    <blockquote data-start="1030" data-end="1104">
    <p data-start="1032" data-end="1104" class="">F1 Score is <strong data-start="1044" data-end="1053">66.7%</strong>, showing the balance between precision and recall.</p>
    </blockquote>
    <hr data-start="1106" data-end="1109" class="">
    <h3 data-start="1111" data-end="1132" class="">üéØ Interpretation</h3>
    <ul data-start="1134" data-end="1281">
    <li data-start="1134" data-end="1219" class="">
    <p data-start="1136" data-end="1219" class="">If your main concern is <strong data-start="1160" data-end="1195">not marking real emails as spam</strong> ‚Üí improve <strong data-start="1206" data-end="1219">precision</strong></p>
    </li>
    <li data-start="1220" data-end="1281" class="">
    <p data-start="1222" data-end="1281" class="">If your goal is to <strong data-start="1241" data-end="1259">catch all spam</strong> ‚Üí focus on <strong data-start="1271" data-end="1281">recall</strong></p>
    </li>
    </ul>
    <p data-start="1283" data-end="1368" class="">Let me know if you'd like to see this visualized in code or a confusion matrix chart!</p></div></div>


<h2>What is the ROC curve? How is AUC useful?</h2>

<div class="markdown prose dark:prose-invert w-full break-words light"><p data-start="0" data-end="159" class="">Great question! The <strong data-start="20" data-end="33">ROC curve</strong> and <strong data-start="38" data-end="45">AUC</strong> are essential tools for evaluating the performance of classification models, especially in binary classification.</p>
    <hr data-start="161" data-end="164" class="">
    <h3 data-start="166" data-end="194" class="">‚úÖ What is the ROC Curve?</h3>
    <p data-start="196" data-end="259" class=""><strong data-start="196" data-end="203">ROC</strong> stands for <strong data-start="215" data-end="252">Receiver Operating Characteristic</strong> curve.</p>
    <p data-start="261" data-end="310" class="">It‚Äôs a plot that shows the <strong data-start="288" data-end="309">trade-off between</strong>:</p>
    <ul data-start="312" data-end="419">
    <li data-start="312" data-end="370" class="">
    <p data-start="314" data-end="370" class=""><strong data-start="314" data-end="342">True Positive Rate (TPR)</strong> = Recall = TP / (TP + FN)</p>
    </li>
    <li data-start="371" data-end="419" class="">
    <p data-start="373" data-end="419" class=""><strong data-start="373" data-end="402">False Positive Rate (FPR)</strong> = FP / (FP + TN)</p>
    </li>
    </ul>
    <hr data-start="421" data-end="424" class="">
    <h3 data-start="426" data-end="452" class="">üìà How ROC Curve Works</h3>
    <p data-start="454" data-end="478" class="">To create the ROC curve:</p>
    <ol data-start="479" data-end="635">
    <li data-start="479" data-end="552" class="">
    <p data-start="482" data-end="552" class="">Vary the <strong data-start="491" data-end="504">threshold</strong> for classifying a positive class (from 0 to 1).</p>
    </li>
    <li data-start="553" data-end="596" class="">
    <p data-start="556" data-end="596" class="">For each threshold, compute TPR and FPR.</p>
    </li>
    <li data-start="597" data-end="635" class="">
    <p data-start="600" data-end="635" class="">Plot TPR (y-axis) vs. FPR (x-axis).</p>
    </li>
    </ol>
    <hr data-start="637" data-end="640" class="">
    <h3 data-start="642" data-end="663" class="">üéØ Interpretation</h3>
    <div class="pointer-events-none relative left-[50%]! flex w-[100cqw] translate-x-[-50%] justify-center *:pointer-events-auto"><div class="tableContainer horzScrollShadows"><table class="min-w-full" data-start="665" data-end="937"><thead data-start="665" data-end="697"><tr data-start="665" data-end="697"><th data-start="665" data-end="686">Point on ROC curve</th><th data-start="686" data-end="697">Meaning</th></tr></thead><tbody data-start="731" data-end="937"><tr data-start="731" data-end="780"><td class="max-w-[calc(var(--thread-content-max-width)*2/3)]" data-start="731" data-end="752">(0, 0)</td><td class="max-w-[calc(var(--thread-content-max-width)*2/3)]" data-start="752" data-end="780">Classify all as negative</td></tr><tr data-start="781" data-end="830"><td class="max-w-[calc(var(--thread-content-max-width)*2/3)]" data-start="781" data-end="802">(1, 1)</td><td class="max-w-[calc(var(--thread-content-max-width)*2/3)]" data-start="802" data-end="830">Classify all as positive</td></tr><tr data-start="831" data-end="890"><td class="max-w-[calc(var(--thread-content-max-width)*2/3)]" data-start="831" data-end="852">(0, 1)</td><td class="max-w-[calc(var(--thread-content-max-width)*2/3)]" data-start="852" data-end="890"><strong data-start="854" data-end="871">Perfect model</strong> (TPR=1, FPR=0) ‚úÖ</td></tr><tr data-start="891" data-end="937"><td class="max-w-[calc(var(--thread-content-max-width)*2/3)]" data-start="891" data-end="912">Diagonal line</td><td class="max-w-[calc(var(--thread-content-max-width)*2/3)]" data-start="912" data-end="937">Random guessing ü§∑‚Äç‚ôÇÔ∏è</td></tr></tbody></table></div></div>
    <hr data-start="939" data-end="942" class="">
    <h3 data-start="944" data-end="963" class="">üßÆ What is AUC?</h3>
    <p data-start="965" data-end="1003" class=""><strong data-start="965" data-end="972">AUC</strong> = <strong data-start="975" data-end="1003">Area Under the ROC Curve</strong></p>
    <ul data-start="1005" data-end="1088">
    <li data-start="1005" data-end="1032" class="">
    <p data-start="1007" data-end="1032" class=""><strong data-start="1007" data-end="1032">Score between 0 and 1</strong></p>
    </li>
    <li data-start="1033" data-end="1088" class="">
    <p data-start="1035" data-end="1088" class="">Measures <strong data-start="1044" data-end="1088">how well the model separates the classes</strong></p>
    </li>
    </ul>
    <div class="pointer-events-none relative left-[50%]! flex w-[100cqw] translate-x-[-50%] justify-center *:pointer-events-auto"><div class="tableContainer horzScrollShadows"><table class="min-w-full" data-start="1090" data-end="1506"><thead data-start="1090" data-end="1140"><tr data-start="1090" data-end="1140"><th data-start="1090" data-end="1102">AUC Value</th><th data-start="1102" data-end="1140">Meaning</th></tr></thead><tbody data-start="1193" data-end="1506"><tr data-start="1193" data-end="1244"><td class="max-w-[calc(var(--thread-content-max-width)*2/3)]" data-start="1193" data-end="1205">1.0</td><td class="max-w-[calc(var(--thread-content-max-width)*2/3)]" data-start="1205" data-end="1244">Perfect classifier üéØ</td></tr><tr data-start="1245" data-end="1296"><td class="max-w-[calc(var(--thread-content-max-width)*2/3)]" data-start="1245" data-end="1257">0.9+</td><td class="max-w-[calc(var(--thread-content-max-width)*2/3)]" data-start="1257" data-end="1296">Excellent</td></tr><tr data-start="1297" data-end="1348"><td class="max-w-[calc(var(--thread-content-max-width)*2/3)]" data-start="1297" data-end="1309">0.8+</td><td class="max-w-[calc(var(--thread-content-max-width)*2/3)]" data-start="1309" data-end="1348">Good</td></tr><tr data-start="1349" data-end="1400"><td class="max-w-[calc(var(--thread-content-max-width)*2/3)]" data-start="1349" data-end="1361">0.7+</td><td class="max-w-[calc(var(--thread-content-max-width)*2/3)]" data-start="1361" data-end="1400">Fair</td></tr><tr data-start="1401" data-end="1454"><td class="max-w-[calc(var(--thread-content-max-width)*2/3)]" data-start="1401" data-end="1413">0.5</td><td class="max-w-[calc(var(--thread-content-max-width)*2/3)]" data-start="1413" data-end="1454">No better than random ü§∑‚Äç‚ôÄÔ∏è</td></tr><tr data-start="1455" data-end="1506"><td class="max-w-[calc(var(--thread-content-max-width)*2/3)]" data-start="1455" data-end="1467">&lt; 0.5</td><td class="max-w-[calc(var(--thread-content-max-width)*2/3)]" data-start="1467" data-end="1506">Worse than random (inverted model?)</td></tr></tbody></table></div></div>
    <hr data-start="1508" data-end="1511" class="">
    <h3 data-start="1513" data-end="1536" class="">üìå Why Use ROC/AUC?</h3>
    <ul data-start="1538" data-end="1741">
    <li data-start="1538" data-end="1613" class="">
    <p data-start="1540" data-end="1613" class=""><strong data-start="1540" data-end="1565">Threshold-independent</strong>: Evaluates model across all possible thresholds</p>
    </li>
    <li data-start="1614" data-end="1686" class="">
    <p data-start="1616" data-end="1686" class=""><strong data-start="1616" data-end="1644">Class imbalance friendly</strong>: Especially useful when one class is rare</p>
    </li>
    <li data-start="1687" data-end="1741" class="">
    <p data-start="1689" data-end="1741" class=""><strong data-start="1689" data-end="1696">AUC</strong> gives a single number summary of performance</p>
    </li>
    </ul>
    <hr data-start="1743" data-end="1746" class="">
    <h3 data-start="1748" data-end="1762" class="">üß† Summary</h3>
    <ul data-start="1764" data-end="1945">
    <li data-start="1764" data-end="1823" class="">
    <p data-start="1766" data-end="1823" class=""><strong data-start="1766" data-end="1779">ROC Curve</strong>: Plots TPR vs. FPR for different thresholds</p>
    </li>
    <li data-start="1824" data-end="1878" class="">
    <p data-start="1826" data-end="1878" class=""><strong data-start="1826" data-end="1833">AUC</strong>: Measures the total area under the ROC curve</p>
    </li>
    <li data-start="1879" data-end="1945" class="">
    <p data-start="1881" data-end="1945" class="">Higher AUC = Better model at classifying positives vs. negatives</p>
    </li>
    </ul>
    <hr data-start="1947" data-end="1950" class="">
    <p data-start="1952" data-end="2031" class="">Let me know if you'd like to plot an ROC curve from a sample dataset in Python!</p></div>

    <hr>

<span style="display: none;">Tags: Technology,Machine Learning,Interview Preparation,</span>